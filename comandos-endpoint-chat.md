√ìtima! Vou trazer exemplos **pr√°ticos e variados** de requisi√ß√µes para o endpoint **`/api/chat`** do **Ollama**, para que voc√™ possa mostrar em aula diferentes cen√°rios de uso.

---

# üìö Exemplos de Requisi√ß√µes ‚Äì `/api/chat` no Ollama

## 1. Conversa simples com contexto

```bash
curl http://localhost:11434/api/chat -d '{
  "model": "llama2",
  "messages": [
    {"role": "system", "content": "Voc√™ √© um professor de hist√≥ria."},
    {"role": "user", "content": "Quem descobriu o Brasil?"}
  ]
}'
```

‚û°Ô∏è O `system` define o papel do modelo, e o `user` envia a pergunta.

---

## 2. Mantendo hist√≥rico de conversa

```bash
curl http://localhost:11434/api/chat -d '{
  "model": "llama2",
  "messages": [
    {"role": "system", "content": "Voc√™ √© um guia tur√≠stico."},
    {"role": "user", "content": "Quais s√£o os pontos tur√≠sticos famosos em Paris?"},
    {"role": "assistant", "content": "Paris √© famosa pela Torre Eiffel, o Louvre e a Catedral de Notre-Dame."},
    {"role": "user", "content": "E em Roma?"}
  ]
}'
```

‚û°Ô∏è O modelo recebe o hist√≥rico e entende que a segunda pergunta tamb√©m √© sobre turismo.

---

## 3. Ajustando par√¢metros (temperature e max\_tokens)

```bash
curl http://localhost:11434/api/chat -d '{
  "model": "llama2",
  "messages": [
    {"role": "user", "content": "Escreva um haicai sobre tecnologia."}
  ],
  "options": {
    "temperature": 0.9,
    "max_tokens": 50
  }
}'
```

‚û°Ô∏è `temperature` alta gera respostas mais criativas.
‚û°Ô∏è `max_tokens` limita o tamanho da resposta.

---

## 4. Streaming de resposta

```bash
curl http://localhost:11434/api/chat -d '{
  "model": "llama2",
  "messages": [
    {"role": "user", "content": "Resuma a teoria da evolu√ß√£o em 3 frases."}
  ],
  "stream": true
}'
```

‚û°Ô∏è A resposta chega em partes (tokens) em tempo real.

---

## 5. Usando m√∫ltiplos roles (multi-turn conversation)

```bash
curl http://localhost:11434/api/chat -d '{
  "model": "llama2",
  "messages": [
    {"role": "system", "content": "Voc√™ √© um especialista em programa√ß√£o."},
    {"role": "user", "content": "Explique o que √© recurs√£o."},
    {"role": "assistant", "content": "Recurs√£o √© uma t√©cnica em que uma fun√ß√£o chama a si mesma."},
    {"role": "user", "content": "Pode dar um exemplo em Python?"}
  ]
}'
```

‚û°Ô∏è O hist√≥rico permite ao modelo conectar as respostas.

---

# üìù Resumo r√°pido

* **`system`** ‚Üí define regras globais de comportamento.
* **`user`** ‚Üí entrada do usu√°rio.
* **`assistant`** ‚Üí resposta anterior do modelo (mant√©m contexto).
* **`options`** ‚Üí ajusta comportamento (`temperature`, `top_p`, `max_tokens`, `num_ctx`).
* **`stream`** ‚Üí habilita resposta em fluxo cont√≠nuo.

---

