
# ğŸ¨ Aula: **Customizing Models**

## ğŸ¯ Objetivo

Ao final desta aula, o aluno serÃ¡ capaz de:

* Entender o que significa **customizar um modelo de linguagem**;
* Personalizar modelos via **Modelfile** (prompts, parÃ¢metros, adapters);
* Criar personas e estilos de resposta;
* Compreender boas prÃ¡ticas de versionamento e deploy local.

---

## ğŸ§© 1. O que significa â€œCustomizar um Modeloâ€

Customizar um modelo Ã© o processo de **ajustar o comportamento, o tom e a funÃ§Ã£o de um LLM** sem precisar reentreinar do zero.

Em vez de treinar novos pesos (como no *fine-tuning*), vocÃª:

* Reutiliza um modelo base (ex: `mistral`, `llama3`, `gemma`);
* Adiciona instruÃ§Ãµes e parÃ¢metros no **Modelfile**;
* Cria um novo modelo â€œderivadoâ€, com comportamento fixo e controlÃ¡vel.

ğŸ“˜ **Analogia:**

> Assim como um *Dockerfile* define como construir uma imagem,
> o *Modelfile* define como â€œreprogramarâ€ o modelo base para uma tarefa especÃ­fica.

---

## ğŸ§  2. Formas de customizaÃ§Ã£o

| Tipo                            | MÃ©todo                      | Exemplo                                  |
| ------------------------------- | --------------------------- | ---------------------------------------- |
| **1. Persona / FunÃ§Ã£o**         | Alterar `SYSTEM`            | â€œVocÃª Ã© um professor de Python.â€         |
| **2. Estilo de resposta**       | Ajustar `PARAMETER`         | `temperature`, `top_p`, `stop`           |
| **3. Formato de output**        | Usar `TEMPLATE`             | ForÃ§ar respostas em JSON, Markdown, etc. |
| **4. Contexto / comportamento** | Inserir `SYSTEM` multilinha | Regras de Ã©tica, foco em produto, etc.   |
| **5. AdaptaÃ§Ã£o leve (LoRA)**    | Incluir `ADAPTER`           | `ADAPTER lora://suporte-appmax`          |

---

## âš™ï¸ 3. Estrutura base para customizaÃ§Ã£o

Exemplo de um Modelfile personalizado:

```bash
# Modelfile: appmax-suporte
FROM mistral

SYSTEM """
VocÃª Ã© um assistente tÃ©cnico da Appmax.
Responda de forma profissional, objetiva e sempre em portuguÃªs.
"""

PARAMETER temperature 0.5
PARAMETER top_p 0.9
PARAMETER num_predict 512

TEMPLATE """
UsuÃ¡rio: {{ .Prompt }}
Suporte TÃ©cnico:
"""
```

Depois:

```bash
ollama create appmax-suporte -f Modelfile
ollama run appmax-suporte
```

---

## ğŸ­ 4. Criando Personas

VocÃª pode moldar o modelo para â€œinterpretar papÃ©isâ€ especÃ­ficos.
Cada persona define *voz, estilo e comportamento*.

### Exemplo 1 â€” Professor de Python

```bash
SYSTEM "VocÃª Ã© um professor de Python que explica conceitos de forma simples e prÃ¡tica."
PARAMETER temperature 0.6
```

### Exemplo 2 â€” Jornalista de tecnologia

```bash
SYSTEM "VocÃª escreve notÃ­cias de tecnologia com linguagem jornalÃ­stica, sem opiniÃµes pessoais."
PARAMETER temperature 0.8
```

### Exemplo 3 â€” Analista de logs

```bash
SYSTEM "VocÃª analisa logs de sistema e responde com um resumo tÃ©cnico em Markdown."
PARAMETER temperature 0.3
PARAMETER num_predict 300
```

---

## ğŸ“„ 5. Personalizando o formato de saÃ­da (TEMPLATE)

A diretiva `TEMPLATE` permite definir **como o modelo recebe e devolve o prompt**.

### Exemplo: Formato pergunta-resposta

```bash
TEMPLATE """
Pergunta: {{ .Prompt }}
Resposta:
"""
```

### Exemplo: Output em JSON

```bash
TEMPLATE """
AnÃ¡lise:
{{ .Prompt }}

Responda no formato JSON:
{
  "resumo": "...",
  "prioridade": "alta|mÃ©dia|baixa"
}
"""
```

ğŸ“Œ Isso garante respostas estruturadas â€” Ãºtil para automaÃ§Ãµes e integraÃ§Ãµes.

---

## ğŸ§¬ 6. Adicionando adaptadores (LoRA)

Quando o Ollama for configurado com suporte a **LoRA adapters**, vocÃª pode combinar modelos base com ajustes de domÃ­nio especÃ­fico.

```bash
FROM llama3
ADAPTER lora://chat-suporte
```

ğŸ’¡ *Use adapters para adaptar um modelo geral a um domÃ­nio (ex: financeiro, jurÃ­dico, tÃ©cnico).*

---

## ğŸ§ª 7. Exemplo prÃ¡tico â€” Criando um modelo â€œAppmax Helperâ€

```bash
# Modelfile
FROM llama3
SYSTEM """
VocÃª Ã© o Appmax Helper â€” um assistente de integraÃ§Ã£o para novos desenvolvedores.
Explique conceitos de API de forma didÃ¡tica e clara.
"""
PARAMETER temperature 0.5
PARAMETER top_p 0.85
TEMPLATE """
UsuÃ¡rio: {{ .Prompt }}
Appmax Helper:
"""
```

Crie e rode:

```bash
ollama create appmax-helper -f Modelfile
ollama run appmax-helper
```

Teste com:

```
Como integrar a API de pagamento via PIX?
```

---

## ğŸ§± 8. Boas prÃ¡ticas de customizaÃ§Ã£o

âœ… **Use nomes claros** (ex: `appmax-helper`, `python-teacher`).
âœ… **Documente** cada alteraÃ§Ã£o com comentÃ¡rios no Modelfile.
âœ… **Teste** diferentes temperaturas antes de fixar.
âœ… **Versione** os Modelfiles com Git (`Modelfile.v1`, `v2` etc).
âœ… **Evite sobrecarregar o SYSTEM** â€” mantenha instruÃ§Ãµes curtas e especÃ­ficas.
âœ… **Padronize o output** (TEMPLATE ou formato JSON) para automaÃ§Ãµes.

---

## ğŸ§© 9. ExercÃ­cio prÃ¡tico

> **Objetivo:** criar um modelo de â€œAnalista de Suporte Appmaxâ€
> com estilo tÃ©cnico, respostas curtas e formato Markdown.

### Passos:

1. Basear-se no modelo `mistral`;
2. SYSTEM: persona tÃ©cnica (suporte Appmax);
3. PARAMETER: `temperature 0.4`, `num_predict 300`;
4. TEMPLATE: saÃ­da em Markdown (`**Problema:** ... **SoluÃ§Ã£o:** ...`);
5. Testar e comparar com o modelo base (`ollama run mistral`).

---

## ğŸ§  10. DiscussÃ£o guiada

ğŸ’¬ **Perguntas para debate:**

* Quando vale a pena criar um novo Modelfile em vez de ajustar o prompt manualmente?
* Quais parÃ¢metros mais influenciam o â€œestiloâ€ de um modelo?
* Como equilibrar criatividade e previsibilidade em um modelo de suporte?
* Que tipos de customizaÃ§Ã£o facilitam automaÃ§Ã£o via API?

---

## ğŸ§¾ 11. ConclusÃ£o

Customizar modelos Ã© o passo essencial para **trazer IA para o contexto da sua empresa ou produto**.
Com pequenas alteraÃ§Ãµes em **SYSTEM**, **PARAMETER** e **TEMPLATE**, vocÃª transforma um modelo genÃ©rico em um **assistente especializado, estÃ¡vel e com identidade prÃ³pria**.

> ğŸ’¡ â€œO poder da IA nÃ£o estÃ¡ sÃ³ no modelo que vocÃª usa, mas em como vocÃª o molda para o seu contexto.â€

---

## ğŸ“š 12. Recursos e leituras complementares

* [DocumentaÃ§Ã£o oficial do Ollama](https://github.com/ollama/ollama)
* [Model customization guide (OpenWebUI)](https://docs.openwebui.com/)
* [Prompt Engineering Handbook (Brev.dev)](https://www.brev.dev/prompt-engineering)
* [LoRA Adapters Overview](https://huggingface.co/docs/peft/index)
