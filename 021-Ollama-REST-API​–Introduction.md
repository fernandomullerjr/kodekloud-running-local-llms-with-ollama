# Ollama REST API‚Äã ‚Äì Introduction

---

# üìö Ollama REST API ‚Äì Introdu√ß√£o

## 1. O que √© a Ollama REST API?

A **Ollama REST API** permite enviar e receber dados de modelos de linguagem (LLMs) de forma program√°tica usando **HTTP**.
Isso significa que voc√™ pode integrar modelos do Ollama em:

* Aplica√ß√µes web
* Scripts e automa√ß√µes
* Interfaces gr√°ficas (ex.: Open WebUI)
* Servi√ßos backend

---

## 2. Fluxo de Comunica√ß√£o

### üîÑ **Fluxo b√°sico**

```
Usu√°rio ‚Üí Aplicativo ‚Üí Ollama API ‚Üí Modelo LLM ‚Üí Ollama API ‚Üí Aplicativo ‚Üí Usu√°rio
```

**Passo a passo:**

1. **Usu√°rio**: envia uma pergunta ou comando.
2. **App**: recebe o input e faz uma requisi√ß√£o HTTP para o Ollama (`/api/generate` ou `/api/chat`).
3. **LLM**: processa a entrada e gera a resposta.
4. **Ollama API**: retorna a resposta ao aplicativo.
5. **App**: exibe o resultado para o usu√°rio.

üí° *Essa arquitetura permite que a l√≥gica da aplica√ß√£o e a IA fiquem desacopladas ‚Äî voc√™ pode trocar o modelo sem mudar o app.*

---

## 3. Endpoints principais

### üìå 3.1 Listar modelos instalados

```bash
GET /api/tags
```

```bash
curl http://localhost:11434/api/tags
```

---

### üìå 3.2 Gerar texto com um prompt simples

```bash
POST /api/generate
```

```bash
curl http://localhost:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "Explique o que √© aprendizado de m√°quina."
}'
```

---

### üìå 3.3 Conversa com contexto (modo chat)

```bash
POST /api/chat
```

```bash
curl http://localhost:11434/api/chat -d '{
  "model": "llama2",
  "messages": [
    {"role": "system", "content": "Voc√™ √© um especialista em tecnologia."},
    {"role": "user", "content": "Explique o conceito de blockchain."}
  ]
}'
```

---

### üìå 3.4 Baixar um modelo

```bash
POST /api/pull
```

```bash
curl http://localhost:11434/api/pull -d '{
  "name": "mistral"
}'
```

---

### üìå 3.5 Remover um modelo

```bash
DELETE /api/delete
```

```bash
curl -X DELETE http://localhost:11434/api/delete -d '{
  "name": "mistral"
}'
```

---

### üìå 3.6 Gerar resposta com par√¢metros avan√ßados

```bash
curl http://localhost:11434/api/generate -d '{
  "model": "llama2",
  "prompt": "Liste 5 ideias de neg√≥cio para 2025",
  "options": {
    "temperature": 0.8,
    "top_p": 0.9,
    "num_ctx": 4096
  }
}'
```

---

## 4. Exemplo de fluxo em c√≥digo (JavaScript)

```javascript
async function askOllama(prompt) {
  const res = await fetch("http://localhost:11434/api/generate", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      model: "llama2",
      prompt: prompt,
      stream: false
    })
  });

  const data = await res.json();
  console.log("Resposta do LLM:", data.response);
}

askOllama("Explique f√≠sica qu√¢ntica em termos simples");
```

---

## 5. Boas pr√°ticas de uso

* **Confirme se o Ollama est√° rodando** (`ollama serve`).
* **Sempre teste** `GET /api/tags` antes para verificar modelos dispon√≠veis.
* Use `stream: true` para **respostas em tempo real**.
* Ajuste `temperature` e `top_p` para controlar criatividade.
* Limite `max_tokens` para evitar respostas muito longas.
* Separe **l√≥gica de aplica√ß√£o** e **processamento LLM** para maior flexibilidade.

---

## 6. Resumo da Aula

| Conceito              | Explica√ß√£o                                                            |
| --------------------- | --------------------------------------------------------------------- |
| **Fluxo**             | Usu√°rio ‚Üí App ‚Üí API ‚Üí LLM ‚Üí API ‚Üí App ‚Üí Usu√°rio                       |
| **API Base**          | `http://localhost:11434`                                              |
| **Endpoints chave**   | `/api/tags`, `/api/generate`, `/api/chat`, `/api/pull`, `/api/delete` |
| **Gera√ß√£o de texto**  | `POST /api/generate` com `prompt`                                     |
| **Chat com contexto** | `POST /api/chat` com `messages`                                       |
| **Par√¢metros √∫teis**  | `temperature`, `top_p`, `num_ctx`, `max_tokens`                       |
| **Boas pr√°ticas**     | Testar conex√£o, controlar contexto, usar streaming quando poss√≠vel    |

---




# üìå Campos e Par√¢metros da Ollama REST API

## 1. Campos Comuns (presentes na maioria das chamadas)

| Campo        | Tipo    | Obrigat√≥rio? | Descri√ß√£o                                                                                                          | Exemplo                                             |
| ------------ | ------- | ------------ | ------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------- |
| **model**    | string  | ‚úÖ            | Nome do modelo instalado no Ollama. Deve aparecer no `/api/tags`.                                                  | `"model": "llama2"`                                 |
| **prompt**   | string  | ‚ö†Ô∏è\*         | Texto ou instru√ß√£o enviada para o modelo (usado em `/api/generate`).                                               | `"prompt": "Explique a teoria da relatividade"`     |
| **messages** | array   | ‚ö†Ô∏è\*         | Lista de mensagens para manter contexto de conversa (usado em `/api/chat`).                                        | `[{"role":"user","content":"Ol√°"}]`                 |
| **stream**   | boolean | ‚ùå            | Se `true`, envia resposta em fluxo cont√≠nuo (streaming). Se `false`, espera a resposta completa antes de devolver. | `"stream": true`                                    |
| **options**  | objeto  | ‚ùå            | Conjunto de par√¢metros para controlar comportamento do modelo.                                                     | `"options": {"temperature":0.7}`                    |
| **system**   | string  | ‚ùå            | Prompt de sistema (define comportamento global do modelo).                                                         | `"system": "Voc√™ √© um especialista em tecnologia."` |
| **template** | string  | ‚ùå            | Modelo de template para formatar a entrada.                                                                        | `"template": "{{prompt}}"`                          |
| **context**  | array   | ‚ùå            | Dados bin√°rios codificados que representam hist√≥rico do modelo (tokens).                                           | N√£o comum para iniciantes.                          |

‚ö†Ô∏è *Ou `prompt` ou `messages` devem ser usados, dependendo do endpoint.*

---

## 2. Campos no Endpoint `/api/generate`

Este endpoint √© usado para **gerar texto sem manter hist√≥rico de conversa**.

```jsonc
{
  "model": "llama2",
  "prompt": "Liste 3 curiosidades sobre intelig√™ncia artificial",
  "stream": false,
  "options": {
    "temperature": 0.7,
    "top_p": 0.9,
    "num_ctx": 4096,
    "repeat_penalty": 1.1,
    "stop": ["\n\n"]
  }
}
```

### Campos do `options` mais comuns:

| Campo               | Tipo  | Padr√£o            | Descri√ß√£o                                                                       |
| ------------------- | ----- | ----------------- | ------------------------------------------------------------------------------- |
| **temperature**     | float | 0.8               | Controla criatividade: baixo = respostas mais objetivas, alto = mais criativas. |
| **top\_p**          | float | 0.9               | Filtra palavras pela soma de probabilidades.                                    |
| **top\_k**          | int   | 40                | Considera apenas as *k* palavras mais prov√°veis.                                |
| **repeat\_penalty** | float | 1.1               | Penaliza repeti√ß√µes excessivas.                                                 |
| **num\_ctx**        | int   | depende do modelo | Janela de contexto (tokens que o modelo ‚Äúlembra‚Äù).                              |
| **max\_tokens**     | int   | ilimitado         | Limita tamanho da resposta.                                                     |
| **stop**            | array | \[]               | Lista de sequ√™ncias que interrompem a gera√ß√£o.                                  |

---

## 3. Campos no Endpoint `/api/chat`

Este endpoint √© usado para **manter hist√≥rico e simular chat**.

```jsonc
{
  "model": "llama2",
  "messages": [
    { "role": "system", "content": "Voc√™ √© um assistente educado e objetivo." },
    { "role": "user", "content": "Quem descobriu o Brasil?" },
    { "role": "assistant", "content": "O Brasil foi oficialmente descoberto em 1500 por Pedro √Ålvares Cabral." }
  ],
  "stream": false,
  "options": {
    "temperature": 0.2
  }
}
```

### Valores para `role`:

* `"system"` ‚Üí Define regras e contexto global.
* `"user"` ‚Üí Mensagens enviadas pelo usu√°rio.
* `"assistant"` ‚Üí Respostas do modelo.

---

## 4. Campos em `/api/pull` (baixar modelo)

```json
{
  "name": "mistral",
  "stream": true
}
```

* **name** ‚Üí Nome do modelo (pode incluir tag de vers√£o).
* **stream** ‚Üí Recebe progresso de download em tempo real.

---

## 5. Campos em `/api/delete` (remover modelo)

```json
{
  "name": "mistral"
}
```

* **name** ‚Üí Nome do modelo a ser removido.

---

## 6. Resumo r√°pido dos campos

| Campo      | Onde usar                     | Fun√ß√£o principal                |
| ---------- | ----------------------------- | ------------------------------- |
| `model`    | todos                         | Define qual LLM ser√° usado      |
| `prompt`   | `/api/generate`               | Entrada direta de texto         |
| `messages` | `/api/chat`                   | Hist√≥rico de conversas          |
| `stream`   | todos                         | Ativa streaming de resposta     |
| `options`  | `/api/generate` e `/api/chat` | Ajusta comportamento            |
| `system`   | `/api/chat`                   | Define o papel e regras do LLM  |
| `template` | `/api/generate`               | Formata entrada                 |
| `context`  | avan√ßado                      | Mant√©m estado entre requisi√ß√µes |

---











-------------------------------------------------------------------------
-------------------------------------------------------------------------
-------------------------------------------------------------------------
-------------------------------------------------------------------------
-------------------------------------------------------------------------
-------------------------------------------------------------------------
-------------------------------------------------------------------------

- Comando para testar


```bash
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-r1:latest",
    "prompt": "Explique o que √© aprendizado de m√°quina.",
    "stream": false
  }'
```


resposta veio zoada:

~~~~bash
^C
> curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-r1:latest",
    "prompt": "Explique o que √© aprendizado de m√°quina.",
    "stream": false
  }'
{"model":"deepseek-r1:latest","created_at":"2025-09-07T01:34:37.530647482Z","response":"\u003cthink\u003e\nOkay, the user asked \"Explicar o que √© aprendizado de m√°quina.\" which translates to explaining what machine learning is in Portuguese. Let me start by understanding their query.\n\nFirst, they might be a Portuguese speaker looking for a clear definition of machine learning. The question seems straightforward but maybe they need it broken down into simple terms. They could be someone new to the field, perhaps a student or a professional curious about AI and ML trends.\n\nSince they're asking in Portuguese, I should make sure my response is also in Portuguese to match their language preference. But wait, the example provided was in English. Hmm, maybe I need to provide both? No, the user wants an explanation in Portuguese according to their query's requirement.\n\nBut let me think deeper. The term \"aprendizado de m√°quina\" is specific to Brazilian Portuguese because of Google Translate examples. So confirming they're likely from Brazil or speak that variant. They might not be familiar with technical jargon, so avoiding complex terms unless necessary.\n\nNow, why are they asking this? Could be for a school project, personal interest, or maybe considering entering the field and wants foundational knowledge. The explanation should cover basics without diving too deep into mathematics or programming details unless asked.\n\nThey might need to distinguish ML from other AI concepts like deep learning or neural networks. Also, clarifying that it's not just about data processing but building models with predictive power is important. Highlighting examples in Portuguese could help them relate better‚Äîlike classificando spam emails, previs√£o de vendas, etc.\n\nAre they possibly looking for career opportunities related to ML? Or maybe how it applies to everyday technologies like chatbots or recommendation systems? Including real-world applications can make the explanation more engaging and show practical relevance.\n\nI should structure the answer starting with a simple definition, then differentiate between machine learning and artificial intelligence. Next, explain that it's about building models from data, followed by examples of tasks. Then describe how ML works in steps: data collection, model building, training, prediction, iteration.\n\nNeed to avoid markdown as per instructions, so keep the response natural with Portuguese terms. Make sure key points are covered without being too technical. Maybe mention supervised and unsupervised learning briefly but not go into detail unless necessary.\n\nCheck if there's a deeper need: perhaps they want to know how ML is used in their industry or if it's accessible for someone without advanced math skills. But since the query is just about defining what machine learning is, sticking to that scope while providing enough context for understanding.\n\nAlso, ensuring clarity on why data is essential and how models improve over time. Emphasize adaptability as a key feature. Maybe touch upon ethical considerations briefly? Not unless specified, but if they're asking broadly, it might be implied. However, the user hasn't indicated that, so better to keep focused on definition.\n\nFinally, summarize ML's role in AI and its practical benefits. Make sure the explanation is approachable for someone unfamiliar with the subject.\n\u003c/think\u003e\nOkay, vamos explicar o Aprendizado de M√°quina em termos simples:\n\n**O que √© Aprendizado de M√°quina?**\n\n√â um subcampo da **Intelig√™ncia Artificial (IA)** que se concentra em *ensinar computadores a aprender tarefas sem programa√ß√£o expl√≠cita*.\n\nImagine: voc√™ quer fazer uma m√°quina realizar alguma coisa inteligente, como classificar fotos, prever resultados futuros, ou identificar padr√µes complexos. Ao inv√©s de dar instru√ß√µes detalhadas para cada caso (como um programa tradicional), voc√™ d√° a ela **exemplos** e faz com que ela \"aprenda\" com esses exemplos.\n\nPense assim:\n\n1.  **Dado:** Voc√™ fornece dados ao computador.\n2.  **Objetivo:** Voc√™ diz qual o objetivo desejado (por exemplo, classificar os dados, prever algo).\n3.  **Aprendizado:** O computador analisa os dados e tenta encontrar padr√µes ou regras que permitam alcan√ßar esse objetivo.\n\n**Como Funciona B√°sico:**\n\n*   Voc√™ coleta uma quantidade grande de **dados** relacionados ao problema (ex.: muitas fotos de gatos anotadas como \"gato\", muitas linhas de vendas passadas, dados sobre alunos e suas notas).\n*   O computador cria um modelo matem√°tico baseado nesses dados. Esse modelo √© uma representa√ß√£o simplificada das regras que o conectam.\n*   Usando esse modelo, o computador pode fazer **previs√µes** ou **classifica√ß√µes** em novos dados que ele nunca viu antes.\n\n**Exemplos T√≠picos de Tarefas do Aprendizado de M√°quina:**\n\n*   **Classifica√ß√£o:** Decidir se um e-mail √© spam ou n√£o, identificar uma imagem como gato/cachorro/humano, analisar o sentimento de uma avalia√ß√£o de produto (positivo/negativo).\n*   **Regress√£o:** Prever quanto um im√≥vel vai custar com base em caracter√≠sticas, estimar a nota m√©dia de um filme no futuro.\n*   **Clusteriza√ß√£o/An√°lise de Agrupamento:** Agrupar documentos semanais ou clientes similares (ex.: encontrar grupos de compradores com comportamentos diferentes).\n*   **Gera√ß√£o de Conte√∫do:** Criar textos, imagens, m√∫sica seguindo padr√µes aprendidos.\n\n**Em Resumo:**\n\nO Aprendizado de M√°quina √© a capacidade dos computadores de *aprender e melhorar com experi√™ncia*, ajustando modelos internos a partir de dados. Ele permite que m√°quinas executem tarefas complexas, tornando-se mais eficientes ou acuradas ao longo do tempo √† medida que recebem mais informa√ß√µes. √â o processo pelo qual a IA vai al√©m da programa√ß√£o r√≠gida e consegue se adaptar e aprender com os dados que processa.","done":true,"done_reason":"stop","context":[151669,43953,2372,297,1709,3958,67346,25846,409,135702,13,151670,151667,198,32313,11,279,1196,4588,330,8033,415,277,297,1709,3958,67346,25846,409,135702,1189,892,46918,311,25021,1128,5662,6832,374,304,42188,13,6771,752,1191,553,8660,862,3239,382,5338,11,807,2578,387,264,42188,18601,3330,369,264,2797,7271,315,5662,6832,13,576,3405,4977,30339,714,7196,807,1184,432,10865,1495,1119,4285,3793,1
709,28730,446,20114,23494,336,259,546,14847,6351,300,11,21145,4883,7806,9870,30369,5385,288,5908,1613,324,11107,14845,1293,78,653,23230,3784,71528,1709,2166,65,336,9870,64066,13,28024,297,58896,27525,5841,264,43090,39486,83669,2994,2025,12967,435,70337,4744,384,390,46106,511,10515,277,384,92717,469,2643,27945,1709,1882,64,13],"total_duration":31409136126,"load_duration":53409271,"prompt_eval_count":12,"prompt_eval_duration":4078852,"eval_count":1243,"eval_duration":31350779663}%              
 ~                      
~~~~




ollama run deepseek-r1:70b

ollama pull deepseek-r1:70b


ollama pull deepseek-r1:70b


> df -h
Filesystem      Size  Used Avail Use% Mounted on
none            7.8G     0  7.8G   0% /usr/lib/modules/5.15.167.4-microsoft-standard-WSL2
none            7.8G  4.0K  7.8G   1% /mnt/wsl
drivers         150G  135G   16G  90% /usr/lib/wsl/drivers
/dev/sdb       1007G   45G  912G   5% /
none            7.8G  120K  7.8G   1% /mnt/wslg
none            7.8G     0  7.8G   0% /usr/lib/wsl/lib
rootfs          7.8G  2.4M  7.8G   1% /init
none            7.8G  6.3M  7.8G   1% /run
none            7.8G     0  7.8G   0% /run/lock
none            7.8G     0  7.8G   0% /run/shm
tmpfs           4.0M     0  4.0M   0% /sys/fs/cgroup
none            7.8G  468K  7.8G   1% /mnt/wslg/versions.txt
none            7.8G  468K  7.8G   1% /mnt/wslg/doc
C:\             150G  135G   16G  90% /mnt/c
G:\             782G  483G  299G  62% /mnt/g
snapfuse        128K  128K     0 100% /snap/bare/5


> ollama pull deepseek-r1:70b
pulling manifest
pulling 4cd576d9aa16:   1% ‚ñï                                                                                                               ‚ñè 297 MB/ 42 GB  8.6 MB/s   1h21m






>
curl -X POST http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-r1:latest",
    "prompt": "Explique COMO FAZER UMA PESQUISA NO GOOGLE.",
    "stream": false
  }' | jq .
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100 11005    0 10884  100   121    272      3  0:00:40  0:00:39  0:00:01  2299
{
  "model": "deepseek-r1:latest",
  "created_at": "2025-09-07T01:56:16.108534148Z",
  "response": "<think>\nBem, o usu√°rio est√° pedindo uma explica√ß√£o sobre como fazer uma pesquisa no Google. Parece ser algu√©m que est√° come√ßando a aprender sobre pesquisas eficientes ou talvez precise de um lembrete r√°pido para otimizar suas habilidades de busca.\n\nVou estruturar minha resposta em etapas claras, pois isso ajuda iniciantes a entenderem o processo passo a passo. Come√ßarei com uma introdu√ß√£o simples para estabelecer contexto antes de mergulhar nos detalhes.\n\nPensando no usu√°rio, provavelmente √© um indiv√≠duo sem experi√™ncia avan√ßada em pesquisas online, talvez seja um estudante ou algu√©m aprendendo habilidades digitais. Ele pode n√£o estar familiarizado com todas as ferramentas e recursos que o Google oferece.\n\nA consulta parece bastante direta - apenas sobre como fazer uma pesquisa no Google. Mas vou assumir que ele quer mais do que isso, ent√£o vou incluir dicas avan√ßadas tamb√©m para ir al√©m da resposta b√°sica.\n\nVou abordar isso em partes: primeiro a pesquisa simples, depois as t√©cnicas mais sofisticadas usando operadores de busca e filtros. Usarei exemplos pr√°ticos porque pesquisar efetivamente √© melhor demonstrado do que explicado por palavras sozinas.\n\nPreciso incluir uma se√ß√£o sobre verifica√ß√£o de resultados para ensinar o usu√°rio a avaliar a qualidade das informa√ß√µes, j√° que isso √© fundamental mas muitas pessoas n√£o param para pensar nisso. Um exemplo pr√°tico pode ajudar aqui - talvez mencionar sites como Google Scholar e Wikipedia com seus respectivos usos.\n\nComo ele escreveu em portugu√™s simples, minha resposta deve manter um tom amig√°vel e evitar jarg√µes muito t√©cnicos. Vou estruturar cada se√ß√£o com uma explica√ß√£o clara seguida por exemplos pr√°ticos.\n</think>\nClaro! Fazer uma pesquisa no Google envolve organizar suas palavras-chave de forma eficiente para obter os melhores resultados poss√≠veis. Segue um guia passo a passo:\n\n---\n\n### **1. Defina sua busca**\n- Especifique claramente o que voc√™ est√° procurando (ex: artigo, not√≠cia, tutorial, etc.).\n\n---\n\n### **2. Use palavras-chave relevantes e espec√≠ficas**\n- Em vez de textos gen√©ricos como \"carro\", use termos mais precisos:\n  - Exemplo: *\"carros el√©tricos 2024 vantagens\"* (busca sobre carros el√©tricos recentes).\n\n---\n\n### **3. Entenda os operadores do Google**\n- **`\"\"`** (*dois espa√ßos duplos*): Encontra exatamente as palavras entre aspas.\n  - Exemplo: `\"receitas de bolo\"` (encontrar√° textos com a frase completa).\n  \n- **`-`**: Exclui resultados que contenham esse termo.\n  - Exemplo: `carros el√©tricos -pre√ßo` (remove menc√µes ao custo).\n\n- **`OR`**: Combina palavras alternativas em uma busca.\n  - Exemplo: `\"sa√∫de mental\" OR \"bem-estar psicol√≥gico\"`.\n\n---\n\n### **4. Aproveite a barra (`/`) para agrupar termos**\n- Use `/` quando desejar que o Google use apenas um dos termos entre as palavras.\n  - Exemplo: `\"/ tecnologia / sustentabilidade\"` (encontra resultados com \"tecnologia\" ou \"sustentabilidade\").\n\n---\n\n### **5. Procure por arquivos espec√≠ficos**\n- Use `.pdf` ou `.docx`, `.txt`, etc., para filtrar documentos:\n  - Exemplo: `\"exerc√≠cios de matem√°tica\" filetype:pdf`.\n\n---\n\n### **6. Especifique o idioma**\n- Adicione `lang:` seguido do c√≥digo da l√≠ngua (ex: `pt-BR` ou `es`).\n  - Exemplo: `\"pre√ßo do petr√≥leo\" lang:pt` para resultados em portugu√™s.\n\n---\n\n### **7. Use datas (`date:`)**\n- Encontre informa√ß√µes espec√≠ficas de um per√≠odo:\n  - Exemplo: `covid vacina date:2023` (busca sobre vacinas da covid em 2023).\n\n---\n\n### **8. Acesse recursos especializados**\n- Sites como *Google Scholar* para artigos acad√™micos.\n- Redes sociais e blogs relevantes com o par√¢metro `site:`:\n  - Exemplo: `site:tweeter.com` para resultados apenas no Twitter.\n\n---\n\n### **9. Filtre os resultados**\n- No menu suspenso do canto superior direito, selecione op√ß√µes como \"Not√≠cias\", \"Imagens\", \"Videos\" ou \"Arquivos\".\n- Use filtros de data, regi√£o e tipo de conte√∫do para refinar sua busca.\n\n---\n\n### **10. Verifique a qualidade das informa√ß√µes**\n- Confira os sites (.org, .edu, .com) antes de usar as informa√ß√µes.\n- Exemplo: `site:wikipedia.org` ou `site:government`.\n\n---\n\n### **Exemplo Pr√°tico**\nSe voc√™ est√° procurando *\"como fazer uma pesquisa no Google com operadores\",* pode digitar:\n```\n\"pesquisa avan√ßada Google\" -tutorial site:.com\n```\n\nIsso ir√° mostrar resultados em sites de dom√≠nio .com sem incluir tutoriais.\n\n---\n\nSiga essas dicas para melhorar sua produtividade na busca por informa√ß√µes!",
  "done": true,
  "done_reason": "stop",
  "context": [
    151669,
    43953,

    0
  ],
  "total_duration": 39967800915,
  "load_duration": 3830598921,
  "prompt_eval_count": 18,
  "prompt_eval_duration": 247251638,
  "eval_count": 1199,
  "eval_duration": 35888819793
}
>

 ~       


## PENDENTE

    Baixar deepseek de 70B que ocupa 40GB.

    Testar deepseek de 70B. Utilizar o JQ para formatar o JSON.




> ollama run deepseek-r1:70b "me mostre um codigo em python que comunica com api do ollama"
Error: 500 Internal Server Error: model requires more system memory (35.6 GiB) than is available (11.4 GiB)

 ~              