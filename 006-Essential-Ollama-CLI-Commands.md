
# Essential Ollama CLI Commands

---


# üìö Comandos Essenciais do Ollama

Este guia re√∫ne os comandos mais importantes do **Ollama** para **gerenciar, executar e personalizar LLMs** localmente.

---

## 1. Instalar um modelo

Baixa e instala um modelo do reposit√≥rio oficial do Ollama.

```bash
ollama pull <modelo>
```

**Exemplo:**

```bash
ollama pull llama2
```

üí° *√â como ‚Äúbaixar um aplicativo‚Äù ‚Äî o modelo fica salvo no seu computador.*

---

## 2. Listar modelos instalados

Mostra todos os modelos que voc√™ j√° baixou.

```bash
ollama list
```

üí° *√ötil para saber quais modelos j√° est√£o dispon√≠veis localmente.*

---

## 3. Ver informa√ß√µes sobre um modelo

Mostra detalhes de um modelo, como arquitetura, par√¢metros, tamanho e data de instala√ß√£o.

```bash
ollama show <modelo>
```

**Exemplo:**

```bash
ollama show llama2
```


> ollama show deepseek-r1:latest
  Model
    architecture        qwen3
    parameters          8.2B
    context length      131072
    embedding length    4096
    quantization        Q4_K_M

  Capabilities
    completion
    thinking

  Parameters
    stop           "<ÔΩúbegin‚ñÅof‚ñÅsentenceÔΩú>"
    stop           "<ÔΩúend‚ñÅof‚ñÅsentenceÔΩú>"
    stop           "<ÔΩúUserÔΩú>"
    stop           "<ÔΩúAssistantÔΩú>"
    temperature    0.6
    top_p          0.95

  License
    MIT License
    Copyright (c) 2023 DeepSeek
    ...


üí° *√â como abrir a ficha t√©cnica do modelo para saber suas especifica√ß√µes.*

---

## 4. Executar um modelo

Inicia o modelo e abre o modo interativo.

```bash
ollama run <modelo>
```

**Exemplo:**

```bash
ollama run mistral
```

üí° *√â como ‚Äúabrir o aplicativo‚Äù e come√ßar a conversar.*

---

## 5. Executar com um prompt direto

Executa o modelo com uma entrada e j√° retorna a resposta, sem entrar no modo interativo.

```bash
ollama run <modelo> "Seu prompt aqui"
```

**Exemplo:**

```bash
ollama run llama2 "Explique a teoria da relatividade de forma simples"
```

---

## 6. Remover um modelo

Apaga um modelo instalado e libera espa√ßo.

```bash
ollama rm <modelo>
```

**Exemplo:**

```bash
ollama rm gemma
```

üí° *Bom para economizar espa√ßo de armazenamento.*

---

## 7. Criar um modelo customizado

Cria um modelo baseado em outro, usando um **Modelfile**.

```bash
ollama create <nome> -f Modelfile
```

**Exemplo:**

```bash
ollama create meu-assistente -f Modelfile
```

---

## 8. Definir par√¢metros no Modelfile

Dentro de um **Modelfile**, voc√™ pode configurar ajustes padr√£o.

**Exemplo:**

```text
FROM llama2
PARAMETER temperature 0.7
PARAMETER top_p 0.9
SYSTEM "Voc√™ √© um especialista em IA."
```

---

## 9. Passar par√¢metros direto na execu√ß√£o

Defina par√¢metros sem precisar criar um Modelfile.

```bash
ollama run <modelo> --temperature 0.2 --top_p 0.8 "Responda de forma t√©cnica"
```

---

## 10. Encerrar execu√ß√£o do modelo

Quando estiver no modo interativo, para encerrar:

* **Ctrl + D** ou
* Digite:

```text
/bye
```

---

## 11. Ver ajuda dos comandos

Mostra todos os comandos e op√ß√µes dispon√≠veis.

```bash
ollama help
```

---

## üìù Resumo R√°pido

| A√ß√£o                          | Comando                             |
| ----------------------------- | ----------------------------------- |
| Instalar modelo               | `ollama pull <modelo>`              |
| Listar modelos                | `ollama list`                       |
| Ver info do modelo            | `ollama show <modelo>`              |
| Executar modelo               | `ollama run <modelo>`               |
| Prompt direto                 | `ollama run <modelo> "texto"`       |
| Remover modelo                | `ollama rm <modelo>`                |
| Criar modelo customizado      | `ollama create <nome> -f Modelfile` |
| Passar par√¢metros na execu√ß√£o | `ollama run <modelo> --param valor` |
| Encerrar execu√ß√£o             | `Ctrl+D` ou `/bye`                  |
| Ajuda                         | `ollama help`                       |

---
